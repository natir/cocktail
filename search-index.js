var searchIndex = JSON.parse('{\
"cocktail":{"doc":"","t":[0,0,0,0,0,0,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,0,0,0,0,3,11,11,11,11,11,11,11,11,11,11,3,11,11,11,11,11,11,11,11,11,11,3,3,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,3,11,11,11,11,11,11,11,11,11,11],"n":["binding","kmer","rle","tokenizer","kmer","tokenizer","cocktail_bit2nuc","cocktail_canonical","cocktail_comp","cocktail_get_first_bit","cocktail_get_hash_space_size","cocktail_get_kmer_space_size","cocktail_hash","cocktail_kmer2seq","cocktail_nuc2bit","cocktail_parity_even","cocktail_remove_first_bit","cocktail_rev","cocktail_revcomp","cocktail_seq2bit","cocktail_minimizerring_add_kmer","cocktail_minimizerring_free","cocktail_minimizerring_get_mini","cocktail_minimizerring_new","cocktail_minimizerring_populate_buffer","bit2nuc","canonical","comp","get_first_bit","get_hash_space_size","get_kmer_space_size","hash","kmer2seq","nuc2bit","parity_even","remove_first_bit","rev","revcomp","seq2bit","rle2bit","rle2kmer","rle2seq","seq2rle","basic","canonical","minimizer","rle","Tokenizer","borrow","borrow_mut","from","into","into_iter","new","next","try_from","try_into","type_id","Canonical","borrow","borrow_mut","from","into","into_iter","new","next","try_from","try_into","type_id","MinimizerRing","TokenizerMini","add_kmer","borrow","borrow","borrow_mut","borrow_mut","from","from","get_mini","into","into","into_iter","new","new","next","populate_buffer","try_from","try_from","try_into","try_into","type_id","type_id","TokenizerRLE","borrow","borrow_mut","from","into","into_iter","new","next","try_from","try_into","type_id"],"q":["cocktail","","","","cocktail::binding","","cocktail::binding::kmer","","","","","","","","","","","","","","cocktail::binding::tokenizer","","","","","cocktail::kmer","","","","","","","","","","","","","","cocktail::rle","","","","cocktail::tokenizer","","","","cocktail::tokenizer::basic","","","","","","","","","","","cocktail::tokenizer::canonical","","","","","","","","","","","cocktail::tokenizer::minimizer","","","","","","","","","","","","","","","","","","","","","","","cocktail::tokenizer::rle","","","","","","","","","",""],"d":["This module contain function for binding a C and Python …","A set of function to convert small sequence (less than 32 …","A set of function to convert DNA sequence in Run Length …","This module provides iterator to produce kmer from DNA …","","","Binding for kmer::bit2nuc in Python the name is bit2nuc","Binding for kmer::canonical in Python the name is canonical","Binding for kmer::comp in Python the name is comp","Binding for kmer::get_first_bit in Python the name is …","Binding for kmer::get_hash_space_size in Python the name …","Binding for kmer::get_kmer_space_size in Python the name …","Binding for kmer::hash in Python the name is hash","Binding for kmer::kmer2seq in Python the name is kmer2seq","Binding for kmer::nuc2bit in Python the name is nuc2bit","Binding for kmer::parity_even in Python the name is …","Binding for kmer::remove_first_bit in Python the name is …","Binding for kmer::rev in Python the name is rev","Binding for kmer::revcomp in Python the name is revcomp","Binding for kmer::seq2bit in Python the name is seq2bit …","Add the next kmer. See MinimizerRing::add_kmer(). In …","Free a cocktail minimizer ring","Get the actual minimizer. See MinimizerRing::get_mini(). …","Create a cocktail MinimizerRing. See MinimizerRing::new(). …","Reset the ring buffer. See MinimizerRing::populate_buffer()…","Convert the 2bit representation of a nucleotide in …","Take a kmer and return the canonical form","Return the complement of kmer","Return true if the right bit of kmer is 1","Return the cardinality of canonical hash set for a given …","Return the cardinality of canonical kmer set for a given …","Take a subseq and return the canonical kmer with out the …","Convert a 2 bit repersentation in String.","Convert a nucleotide in 2bit representation, by use …","Return true if the kmer parity is even","Return the kmer without the rightest bit of kmer","Return the reverse of kmer","Return the reverse complement of kmer","Convert a sequence in 2 bit representation if suseq is …","Convert a rle in 2bit representation repetition is ignore.","Convert a rle sequence in 2 bit representation repetition …","Convert a rle in String.","Convert a sequence in rle representation","","","","","An iterator that takes a DNA sequence and produces kmers, …","","","","","","Create a new Tokenizer on seq DNA kmer size is equal to k","","","","","An iterator that takes a DNA sequence and produces kmers, …","","","","","","Create a new Canonical tokenizer on seq DNA, kmer size is …","","","","","A struct to get minimizer of sucessive kmer","An iterator that takes a DNA sequence and produces kmers …","Add the next kmer","","","","","","","Get a pair of value first one is the minimizer second one …","","","","Create a new TokenizerMini on seq DNA kmer size is equal …","Create a MinimizerRing, with kmer size equale to <code>k</code>, …","","Reset the ring buffer with a new kmer","","","","","","","An iterator that takes a DNA sequence and produces kmers, …","","","","","","Create a new TokenizerRLE on seq DNA kmer size is equal to …","","","",""],"i":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,0,2,2,2,2,2,2,2,2,2,2,0,0,3,4,3,4,3,4,3,3,4,3,4,4,3,4,3,4,3,4,3,4,3,0,5,5,5,5,5,5,5,5,5,5],"f":[null,null,null,null,null,null,[[["u64",15]],["u8",15]],[[["u64",15],["u8",15]],["u64",15]],[[["u64",15],["u8",15]],["u64",15]],[[["u64",15]],["bool",15]],[[["u8",15]],["u64",15]],[[["u8",15]],["u64",15]],[[["u8",15]],["u64",15]],[[["u64",15],["u8",15]]],[[["u8",15]],["u64",15]],[[["u64",15]],["bool",15]],[[["u64",15]],["u64",15]],[[["u64",15],["u8",15]],["u64",15]],[[["u64",15],["u8",15]],["u64",15]],[[["usize",15]],["u64",15]],[[["u64",15],["minimizerring",3]]],[[]],[[["minimizerring",3]],["u64",15]],[[["u64",15],["u8",15]]],[[["u64",15],["minimizerring",3]]],[[["u64",15]],["u8",15]],[[["u64",15],["u8",15]],["u64",15]],[[["u64",15],["u8",15]],["u64",15]],[[["u64",15]],["bool",15]],[[["u8",15]],["u64",15]],[[["u8",15]],["u64",15]],[[["u8",15]],["u64",15]],[[["u64",15],["u8",15]],["string",3]],[[["u8",15]],["u64",15]],[[["u64",15]],["bool",15]],[[["u64",15]],["u64",15]],[[["u64",15],["u8",15]],["u64",15]],[[["u64",15],["u8",15]],["u64",15]],[[],["u64",15]],[[["u8",15]],["u64",15]],[[],["u64",15]],[[],["string",3]],[[],["box",3]],null,null,null,null,null,[[]],[[]],[[]],[[]],[[]],[[["u8",15]]],[[],["option",4]],[[],["result",4]],[[],["result",4]],[[],["typeid",3]],null,[[]],[[]],[[]],[[]],[[]],[[["u8",15]]],[[],["option",4]],[[],["result",4]],[[],["result",4]],[[],["typeid",3]],null,null,[[["u64",15]]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[["u8",15]]],[[["u64",15],["u8",15]]],[[],["option",4]],[[["u64",15]]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["typeid",3]],[[],["typeid",3]],null,[[]],[[]],[[]],[[]],[[]],[[["u8",15]]],[[],["option",4]],[[],["result",4]],[[],["result",4]],[[],["typeid",3]]],"p":[[3,"Tokenizer"],[3,"Canonical"],[3,"MinimizerRing"],[3,"TokenizerMini"],[3,"TokenizerRLE"]]}\
}');
if (window.initSearch) {window.initSearch(searchIndex)};